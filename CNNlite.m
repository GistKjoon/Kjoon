%% tanh 활성화 함수를 사용하는 간단한 CNN Forward/Backward 예시
%  - 입력 (X)는 단일 채널
%  - 필터 (W)는 단일 필터
%  - 편향 (b)는 상수 1
%  - 활성화 함수: tanh

clear; clc;  % 워크스페이스와 콘솔 정리

%% -----------------------------
% 1. 입력 및 파라미터 초기화
% -----------------------------
X = rand(5, 5);        % (5x5) 크기의 입력 행렬 (단일 채널)
W = rand(3, 3);        % (3x3) 크기의 필터 (단일 필터)
b = 1;                 % 편향을 상수 1로 고정
learning_rate = 0.01;  % 학습률(가중치 업데이트 시 사용 예)

%% -----------------------------
% 2. Forward Propagation
% -----------------------------
% 2.1 합성곱 연산
%     - MATLAB의 conv2 함수를 사용 (기본적으로 풀네임 'conv2(X, W)'는 
%       2D 컨벌루션 수행. 여기서는 'valid' 옵션으로 출력 크기를 축소)
Z = conv2(X, W, 'valid') + b;  
%  => Z의 크기는 (5-3+1) x (5-3+1) = 3 x 3

% 2.2 tanh 활성화 적용
A = tanh(Z);

% Forward 결과 출력 (디스플레이 용)
disp('----- Forward 결과 -----');
disp('Z (합성곱 + b) =');
disp(Z);
disp('A (tanh(Z)) =');
disp(A);

%% -----------------------------
% 3. Backward Propagation
% -----------------------------
%  여기서는 "출력에 대한 손실(L)의 기울기 dL/dA"가 주어졌다고 가정하고
%  (예: 임의의 gradient를 생성), 이를 통해
%  1) dL/dZ
%  2) dL/dW
%  3) dL/dX
%  를 순서대로 구합니다.

% 3.1 dL/dA를 임의로 정의 (실제 학습 상황에서는 역전파로부터 넘어옴)
dA = rand(size(A));  % A와 같은 크기의 임의 값

% 3.2 dL/dZ 계산
%     - 체인룰: dL/dZ = dL/dA * dA/dZ
%     - tanh'(Z) = 1 - tanh(Z)^2 = 1 - A^2
dZ = dA .* (1 - A.^2);

% 3.3 dL/dW 계산
%     - 합성곱 계층에서 W에 대한 미분은, dZ와 X의 역합성곱(transposed conv)
%       개념으로 구할 수 있음.
%     - MATLAB에서는 간단히 conv2(X, rot90(dZ,2), 'valid') 등을 사용할 수 있음.
%       다만 옵션이나 rot90 횟수는 구현 목적에 따라 달라질 수 있음.
dW = conv2(X, rot90(dZ, 2), 'valid');  
%  => rot90(dZ,2)는 dZ를 180도 회전한 것
%     ('valid' 모드는 W와 같은 크기를 얻기 위함)

%  편향 b는 상수로 고정이지만, 만약 b가 학습 대상이라고 가정하면
%     dL/db = sum(dZ(:));  % Z 전체에 대한 편향 기여 합
%  이 될 것입니다.
%  여기서는 b가 constant라고 했으므로, 편향에 대한 업데이트는 생략합니다.

% 3.4 dL/dX 계산
%     - 입력 X에 대한 미분도, dZ와 W의 'full' 컨벌루션으로 구할 수 있음.
%     - dX = conv2(dZ, rot90(W,2), 'full')
dX = conv2(dZ, rot90(W, 2), 'full');

% Backward 결과 출력 (디스플레이 용)
disp('----- Backward 결과 -----');
disp('dZ = dA .* (1 - A.^2) =');
disp(dZ);
disp('dW = conv2(X, rot90(dZ, 2), ''valid'') =');
disp(dW);
disp('dX = conv2(dZ, rot90(W, 2), ''full'') =');
disp(dX);

%% -----------------------------
% 4. 가중치 업데이트 (예시)
% -----------------------------
%  - 실제 학습 시에는 dW를 이용해 W를 업데이트.
%  - b는 상수이므로 업데이트 X
%  - 여기서는 예시로만 업데이트를 보여줌.

W_new = W - learning_rate * dW;  % 가중치 업데이트
% b는 상수이므로 업데이트 하지 않음 (b = 1)

disp('----- 업데이트된 가중치 -----');
disp('W_new =');
disp(W_new);
